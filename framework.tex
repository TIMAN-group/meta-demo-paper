\section{A Unified Framework}
\label{sec:framework}

The existing environment of open source software solutions for text processing
is fragmented: there is rarely a single location for a wide variety of
algorithms. Tools tend to specialize on one particular area, and as such there
is a wide variety of tools one must sample when performing different data
science tasks. For text-mining tasks, this is even more apparent; it is
extremely difficult (if not impossible) to find tools that support both
traditional information retrieval tasks (like tokenization, indexing, and
search) alongside traditional machine learning tasks (like document
classification, regression, and topic modeling).

Data science students, researchers, and practitioners must find the appropriate
software packages for their needs and compile and configure each appropriate
tool. Then, there is the problem of data formatting---it is unlikely that the
tools all have standardized upon a single input format, so a certain amount of
``data munging'' is required. All of this detracts from the actual task at hand,
which has a marked impact on productivity.

The goal of the \meta/ project is to address these issues. In particular, we
provide a unifying framework for existing machine learning and natural language
processing algorithms, allowing researchers to quickly run controlled
experiments. We have modularized the feature generation, instance
representation, data storage formats, and algorithm implementations; this allows
for researchers, practitioners, and students to make seamless transitions along
any of these dimensions with minimal effort.

We have a liberal licensing scheme for \meta/. It is dual-licensed under the
University of Illinois/NCSA Open Source Licence and the MIT License in order to
reach the broadest audience possible.

\begin{table*}[t]
    \begin{center}
    {\small
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|}
        \hline
        & \textbf{Indri} & \textbf{Lucene} & \textbf{MALLET} &
        \textbf{LIBLINEAR} & \textbf{SVM$^{MULT}$} & \textbf{scikit} &
        \textbf{CoreNLP} & \textbf{\meta/} \\
        \hline
        Feature generation & \checkmark & \checkmark & \checkmark & & &
        \checkmark & \checkmark & \checkmark \\
        Search & \checkmark & \checkmark & & & & & & \checkmark \\
        Classification & & & \checkmark & \checkmark & \checkmark & \checkmark &
        & \checkmark \\
        Regression & & & \checkmark & \checkmark & \checkmark & \checkmark & &
        \checkmark \\
        POS tagging & & & \checkmark & & & & \checkmark & \checkmark \\
        Parsing & & & & & & & \checkmark & \checkmark \\
        Topic models & & & \checkmark & & & & & \checkmark \\
        Language models & & & & & & & & \checkmark \\
        Word embeddings & & & & & & & \checkmark & \checkmark \\
        Graph algorithms & & & & & & & & \checkmark \\
        Multithreading & & \checkmark & \checkmark & & & \checkmark & \checkmark
        & \checkmark \\
        \hline
    \end{tabular}
    \label{tab:feature-comp}
    \caption{Feature comparison of NLP, IR, and ML toolkits.}
    }
    \end{center}
\end{table*}

Table~\ref{tab:feature-comp} compares \meta/'s many features across various
toolkits. Due to space constraints, we only delve into the natural language
processing (NLP), information retrieval (IR), and machine learning (ML)
components in section~\ref{sec:experiments}. We briefly outline all components
here:

% might just convert to paragraphs with bolded "headers"
\begin{itemize}
    \item Feature generation
    \todo{Mention demos where available.}
    \item Search
    \item Classification
    \item Regression
    \item POS tagging
    \item Parsing
    \item Topic models
    \item Language models
    \item Word embeddings
    \item Graph algorithms
    \item Multithreading
\end{itemize}
